// An implementation of "A Lightweight Stemmer for Hindi":
// http://www.kbcs.in/downloads/papers/StmmerHindi.pdf

externals ( stem )

stringescapes {}

// The transliteration scheme used for our stringdefs matches that used in the
// paper, as documented in the appendix.  It appears to match the WX notation
// (https://en.wikipedia.org/wiki/WX_notation) except that WX apparently
// uses 'z' for Anunasika whereas the paper uses Mh.

// Vowels and sonorants:
stringdef a  '{U+0905}'
stringdef A  '{U+0906}'
stringdef i  '{U+0907}'
stringdef I  '{U+0908}'
stringdef u  '{U+0909}'
stringdef U  '{U+090A}'
stringdef q  '{U+090B}'
stringdef e  '{U+090F}'
stringdef E  '{U+0910}'
stringdef o  '{U+0913}'
stringdef O  '{U+0914}'

// Vowel signs:
stringdef _A '{U+093E}'
stringdef _i '{U+093F}'
stringdef _I '{U+0940}'
stringdef _u '{U+0941}'
stringdef _U '{U+0942}'
stringdef _q '{U+0943}'
stringdef _e '{U+0947}'
stringdef _E '{U+0948}'
stringdef _o '{U+094B}'
stringdef _O '{U+094C}'

// Diacritics:
stringdef M  '{U+0902}'
stringdef H  '{U+0903}'
stringdef Mh '{U+0901}'

// Velar consonants:
stringdef k  '{U+0915}'
stringdef K  '{U+0916}'
stringdef g  '{U+0917}'
stringdef G  '{U+0918}'
stringdef f  '{U+0919}'

// Palatal consonants:
stringdef c  '{U+091A}'
stringdef C  '{U+091B}'
stringdef j  '{U+091C}'
stringdef J  '{U+091D}'
stringdef F  '{U+091E}'

// Retroflex consonants:
stringdef t  '{U+091F}'
stringdef T  '{U+0920}'
stringdef d  '{U+0921}'
stringdef D  '{U+0922}'
stringdef N  '{U+0923}'

// Dental consonants:
stringdef w  '{U+0924}'
stringdef W  '{U+0925}'
stringdef x  '{U+0926}'
stringdef X  '{U+0927}'
stringdef n  '{U+0928}'

// Labial consonants:
stringdef p  '{U+092A}'
stringdef P  '{U+092B}'
stringdef b  '{U+092C}'
stringdef B  '{U+092D}'
stringdef m  '{U+092E}'

// Semi-vowels:
stringdef y  '{U+092F}'
stringdef r  '{U+0930}'
stringdef l  '{U+0932}'
stringdef v  '{U+0935}'

// Fricatives:
stringdef S  '{U+0936}'
stringdef R  '{U+0937}'
stringdef s  '{U+0938}'
stringdef h  '{U+0939}'

integers ( p )

define stem as (
    test ( next setmark p )
    backwards (
        // We assume in this implementation that the whole word doesn't count
        // as a valid suffix to remove, so we remove the longest suffix from
        // the list which leaves at least one character.  This change affects
        // 10 words out of the 65,140 in the sample vocabulary from Hindi
        // wikipedia.  FIXME: Recalculate after changes finalised.
        setlimit tomark p for ([substring])
        among (
            // The list below is taken from figure 3 in the paper.  We perform
            // the stemming on the Devanagari characters rather than
            // transliterating to Latin, so we have adapted the list below to
            // reflect this:
            //
            // * within the suffixes, "a" after a consonant is dropped since
            //   consonants have an implicit "a".
            // * within the suffixes, a vowel other than "a" after a consonant
            //   is a dependent vowel (vowel sign); a vowel (including "a")
            //   after a non-consonant is an independent vowel.
            // * at the start of the suffix, "a" is dropped and other vowels
            //   are dependent vowels (assuming that the suffix follows a
            //   consonant - FIXME: Should we also include each suffix with the
            //   initial vowel as an independent vowel?  Doing so affects 633
            //   of the 65,140 words in the sample vocabulary, so under 1%)
            //
            // We've also assumed that Mh in that list always means {Mh} and
            // never {M}{h}<VIRAMA>.  Only one of the 65,140 words in the sample
            // vocabulary stems differently due to this (and that word seems to
            // be a typo).
            //
            // FIXME: Handle U+094D DEVANAGARI SIGN VIRAMA?
            '{_A}'
            '{_i}'
            '{_I}'
            '{_u}'
            '{_U}'
            '{_e}'
            '{_o}'
            '{_e}{M}'
            '{_o}{M}'
            '{_A}{M}'
            '{_u}{A}{M}'
            '{_u}{e}{M}'
            '{_u}{o}{M}'
            '{_A}{e}{M}'
            '{_A}{o}{M}'
            '{_i}{y}{_A}{M}'
            '{_i}{y}{_o}{M}'
            '{_A}{i}{y}{_A}{M}'
            '{_A}{i}{y}{_o}{M}'
            '{_A}{Mh}'
            '{_i}{y}{_A}{Mh}'
            '{_A}{i}{y}{_A}{Mh}'
            /* '{a}' */ '{w}{_A}{e}{M}'
            /* '{a}' */ '{w}{_A}{o}{M}'
            /* '{a}' */ '{n}{_A}{e}{M}'
            /* '{a}' */ '{n}{_A}{o}{M}'
            /* '{a}' */ '{w}{_A}'
            /* '{a}' */ '{w}{_I}'
            '{_I}{M}'
            /* '{a}' */ '{w}{_I}{M}'
            /* '{a}' */ '{w}{_e}'
            '{_A}{w}{_A}'
            '{_A}{w}{_I}'
            '{_A}{w}{_I}{M}'
            '{_A}{w}{_e}'
            /* '{a}' */ '{n}{_A}'
            /* '{a}' */ '{n}{_I}'
            /* '{a}' */ '{n}{_e}'
            '{_A}{n}{_A}'
            '{_A}{n}{_e}'
            '{_U}{M}{g}{_A}'
            '{_U}{M}{g}{_I}'
            '{_A}{U}{M}{g}{_A}'
            '{_A}{U}{M}{g}{_I}'
            '{_e}{M}{g}{_e}'
            '{_e}{M}{g}{_I}'
            '{_A}{e}{M}{g}{_e}'
            '{_A}{e}{M}{g}{_I}'
            '{_o}{g}{_e}'
            '{_o}{g}{_I}'
            '{_A}{o}{g}{_e}'
            '{_A}{o}{g}{_I}'
            '{_e}{g}{_A}'
            '{_e}{g}{_I}'
            '{_A}{e}{g}{_A}'
            '{_A}{e}{g}{_I}'
            '{_A}{y}{_A}'
            '{_A}{e}'
            '{_A}{I}'
            '{_A}{I}{M}'
            '{_i}{e}'
            '{_A}{o}'
            '{_A}{i}{e}'
            /* '{a}' */ '{k}{r}'
            '{_A}{k}{r}'
                (delete)
    ))
)
